# Vision Transformer for CIFAR-10 & Multi-View Classification

This project demonstrates a complete MLOps workflow for training Vision Transformer (ViT) models on two distinct image classification tasks: standard CIFAR-10 classification and a simulated multi-view medical classification problem. The project is designed for reproducibility, scalability, and easy deployment, leveraging best practices such as containerization with Docker and automated testing with GitHub Actions.

## Project Overview

The repository contains two main training scripts:

1.  **`src/train_cifar10.py`**: A standard fine-tuning pipeline for a `vit_tiny` model on the CIFAR-10 dataset.
2.  **`src/train_multiview.py`**: A more advanced demonstration of Parameter-Efficient Fine-Tuning (PEFT) using **adapters** for a multi-view classification task. This script uses dummy data and is designed to showcase an innovative, memory-efficient architecture.

## Folder Structure

-   **`.github/`**: Contains GitHub Actions workflows for continuous integration.
-   **`configs/`**: Stores YAML files (`config.yaml` and `multiview_config.yaml`) for managing hyperparameters.
-   **`src/`**: The main source code directory, including both training scripts.
-   **`Dockerfile`**: Defines the Docker environment for a consistent runtime.
-   **`requirements.txt`**: Lists all necessary Python dependencies.

## Setup and Installation

### Prerequisites

-   Docker installed on your system.
-   Python 3.8+
-   A NVIDIA GPU with CUDA drivers (for GPU support).

### Local Environment Setup

1.  **Navigate to your projects directory:**
    ```bash
    cd /path/to/MLPractice/GithubProjects/your_repo
    ```

2.  **Activate your virtual environment:**
    ```bash
    source ../sklearn-pytorch-env-py312/bin/activate  # On Windows, use `..\\sklearn-pytorch-env-py312\\Scripts\\activate`
    ```
    
### Generating `requirements.txt`

The `requirements.txt` file can be automatically generated by scanning your source code for imported libraries. This ensures your dependency list is always accurate and minimal.

1.  **Install `pipreqs`:**
    ```bash
    pip install pipreqs
    ```

2.  **Generate the file:**
    ```bash
    pipreqs . --force
    ```

This command will create a `requirements.txt` file at the root of your project, listing only the libraries your code directly imports.

3.  **Install dependencies from the generated file:**
    ```bash
    pip install -r requirements.txt
    ```

## Training the Models

You can run each training script from the command line, referencing its respective configuration file.

### For CIFAR-10 Classification:

```bash
python src/train_cifar10.py
```

###For Multi-View Classification with Adapters:

```bash
python src/train_multiview.py
```